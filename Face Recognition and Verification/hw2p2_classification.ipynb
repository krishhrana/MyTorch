{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW2P2: Face Classification and Verification\n"
      ],
      "metadata": {
        "id": "XBITN0M_LKds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats on coming to the second homework in 11785: Introduction to Deep Learning. This homework significantly longer and tougher than the previous homework. You have 2 sub-parts as outlined below. Please start early! \n",
        "\n",
        "\n",
        "*   Face Recognition: You will be writing your own CNN model to tackle the problem of classification, consisting of 7000 identities\n",
        "*   Face Verification: You use the model trained for classification to evaluate the quality of its feature embeddings, by comparing the similarity of known and unknown identities"
      ],
      "metadata": {
        "id": "-NH4P-HzLRQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common errors which you may face in this homeworks (because of the size of the model)\n",
        "\n",
        "\n",
        "*   CUDA Out of Memory (OOM): You can tackle this problem by (1) Reducing the batch size (2) Calling `torch.cuda.empty_cache()` and `gc.collect()` (3) Finally restarting the runtime\n",
        "\n"
      ],
      "metadata": {
        "id": "i1B_m84_cU6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries"
      ],
      "metadata": {
        "id": "BdoDIKWOMF59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"krishrana1\",\"key\":\"5707cd08227cabf3cbe71910cb2ea9de\"}') \n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HYBqP1vZcsJ",
        "outputId": "e200f6ad-9ad4-42e6-9777-33af0d97e076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73272 sha256=da2dbc7ccd5b591543c2e9cfcc30dedc3158d56931e678dd8da9e896ac689931\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/02/ef/3f8c8d86b8d5388a1d3155876837f1a1a3143ab3fc2ff1ffad\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.13\n",
            "    Uninstalling kaggle-1.5.13:\n",
            "      Successfully uninstalled kaggle-1.5.13\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/data'\n",
        "\n",
        "#!kaggle competitions download -c 11-785-s23-hw2p2-classification\n",
        "#!unzip -qo '11-785-s23-hw2p2-classification.zip' -d '/content/data'\n",
        "\n",
        "!kaggle competitions download -c 11-785-s23-hw2p2-classification\n",
        "!unzip -qo '11-785-s23-hw2p2-classification.zip' -d '/content/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpeX9yvtZnuX",
        "outputId": "e4e518b0-e709-436a-b758-b47620c899c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-s23-hw2p2-classification.zip to /content\n",
            "100% 1.71G/1.72G [01:16<00:00, 25.1MB/s]\n",
            "100% 1.72G/1.72G [01:16<00:00, 24.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMUoPSxUnoJ9",
        "outputId": "8a40e7f8-109a-480c-a51e-48c0a78d7876"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # to see what GPU you have"
      ],
      "metadata": {
        "id": "Jza7lwiScUhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4c1c11-62e0-4a87-b9f7-0ccff83b0ff1",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 19 04:34:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary wandb --quiet"
      ],
      "metadata": {
        "id": "bTxfd_nqFnL9",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f5e906-59f2-4d27-d2e2-1e06e8344a85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "import torchvision #This library is used for image-based operations (Augmentations)\n",
        "import os\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import glob\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwLEd0gdPbSc",
        "outputId": "06a2cbf2-b685-4d65-b7fd-5d31b40fa26c",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:11:47.580299Z",
          "iopub.execute_input": "2023-03-14T04:11:47.581444Z",
          "iopub.status.idle": "2023-03-14T04:11:50.049726Z",
          "shell.execute_reply.started": "2023-03-14T04:11:47.581395Z",
          "shell.execute_reply": "2023-03-14T04:11:50.047663Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'batch_size': 128, # Increase this if your GPU can handle it\n",
        "    'lr': 0.001,\n",
        "    'epochs': 80, # 10 epochs is recommended ONLY for the early submission - you will have to train for much longer typically.\n",
        "    # Include other parameters as needed.\n",
        "}"
      ],
      "metadata": {
        "id": "S7qpMxG0XCJz",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:11:50.052281Z",
          "iopub.execute_input": "2023-03-14T04:11:50.052990Z",
          "iopub.status.idle": "2023-03-14T04:11:50.058669Z",
          "shell.execute_reply.started": "2023-03-14T04:11:50.052943Z",
          "shell.execute_reply": "2023-03-14T04:11:50.057268Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Dataset"
      ],
      "metadata": {
        "id": "sSeiKHYrM-6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''DATA_DIR    = '/content/data/11-785-s23-hw2p2-classification'# TODO: Path where you have downloaded the data\n",
        "TRAIN_DIR   = os.path.join(DATA_DIR, \"train\") \n",
        "VAL_DIR     = os.path.join(DATA_DIR, \"dev\")\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor() \n",
        "])\n",
        "\n",
        "train_dataset   = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_dataset, \n",
        "    batch_size  = config['batch_size'], \n",
        "    #shuffle     = True,\n",
        "    num_workers = 4, \n",
        "    pin_memory  = True\n",
        ")\n",
        "\n",
        "mean, std = batch_mean_and_sd(train_loader)\n",
        "print(mean, std)'''"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "wQmKoMYGZYog",
        "outputId": "9145358a-2199-4a4f-f2d6-25c6cac14e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DATA_DIR    = \\'/content/data/11-785-s23-hw2p2-classification\\'# TODO: Path where you have downloaded the data\\nTRAIN_DIR   = os.path.join(DATA_DIR, \"train\") \\nVAL_DIR     = os.path.join(DATA_DIR, \"dev\")\\n\\ntrain_transforms = torchvision.transforms.Compose([\\n    torchvision.transforms.ToTensor() \\n])\\n\\ntrain_dataset   = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\\n\\ntrain_loader = torch.utils.data.DataLoader(\\n    dataset     = train_dataset, \\n    batch_size  = config[\\'batch_size\\'], \\n    #shuffle     = True,\\n    num_workers = 4, \\n    pin_memory  = True\\n)\\n\\nmean, std = batch_mean_and_sd(train_loader)\\nprint(mean, std)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR    = '/content/data/11-785-s23-hw2p2-classification'# TODO: Path where you have downloaded the data\n",
        "TRAIN_DIR   = os.path.join(DATA_DIR, \"train\") \n",
        "VAL_DIR     = os.path.join(DATA_DIR, \"dev\")\n",
        "\n",
        "# Transforms using torchvision - Refer https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(0.3),\n",
        "    torchvision.transforms.RandomRotation(10),\n",
        "    torchvision.transforms.ColorJitter(brightness=.5, hue=.3),\n",
        "    torchvision.transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
        "    torchvision.transforms.ToTensor(), \n",
        "    torchvision.transforms.Normalize(mean = [0.5116, 0.4026, 0.3519], std = [0.3073, 0.2697, 0.2587])\n",
        "])# Implementing the right train transforms/augmentation methods is key to improving performance.\n",
        "\n",
        "# Most torchvision transforms are done on PIL images. So you convert it into a tensor at the end with ToTensor()\n",
        "# But there are some transforms which are performed after ToTensor() : e.g - Normalization\n",
        "# Normalization Tip - Do not blindly use normalization that is not suitable for this dataset\n",
        "\n",
        "valid_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(), \n",
        "    torchvision.transforms.Normalize(mean = [0.5116, 0.4026, 0.3519], std = [0.3073, 0.2697, 0.2587])\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset   = torchvision.datasets.ImageFolder(TRAIN_DIR, transform= train_transforms)\n",
        "valid_dataset   = torchvision.datasets.ImageFolder(VAL_DIR, transform= valid_transforms)\n",
        "# You should NOT have data augmentation on the validation set. Why?\n",
        "\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_dataset, \n",
        "    batch_size  = config['batch_size'], \n",
        "    shuffle     = True,\n",
        "    num_workers = 4, \n",
        "    pin_memory  = True\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = valid_dataset, \n",
        "    batch_size  = config['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = 2\n",
        ")"
      ],
      "metadata": {
        "id": "tmRX5omaNDEZ",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:12:34.066333Z",
          "iopub.execute_input": "2023-03-14T04:12:34.067147Z",
          "iopub.status.idle": "2023-03-14T04:12:43.248272Z",
          "shell.execute_reply.started": "2023-03-14T04:12:34.067104Z",
          "shell.execute_reply": "2023-03-14T04:12:43.247051Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of classes    : \", len(train_dataset.classes))\n",
        "print(\"No. of train images  : \", train_dataset.__len__())\n",
        "print(\"Shape of image       : \", train_dataset[0][0].shape)\n",
        "print(\"Batch size           : \", config['batch_size'])\n",
        "print(\"Train batches        : \", train_loader.__len__())\n",
        "print(\"Val batches          : \", valid_loader.__len__())"
      ],
      "metadata": {
        "id": "x4t8eU9gY0Jy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613c3b43-4edc-4fa5-995b-8cfbd5a304d4",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:14:31.127575Z",
          "iopub.execute_input": "2023-03-14T04:14:31.128246Z",
          "iopub.status.idle": "2023-03-14T04:14:31.152110Z",
          "shell.execute_reply.started": "2023-03-14T04:14:31.128208Z",
          "shell.execute_reply": "2023-03-14T04:14:31.151099Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes    :  7000\n",
            "No. of train images  :  140000\n",
            "Shape of image       :  torch.Size([3, 224, 224])\n",
            "Batch size           :  64\n",
            "Train batches        :  2188\n",
            "Val batches          :  547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization"
      ],
      "metadata": {
        "id": "zs2Xw_tl0IQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Very Simple Network (for Mandatory Early Submission)"
      ],
      "metadata": {
        "id": "mIqmojPaWD0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I have referenced https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/ while building ResNet. \n",
        "# The layer names are similar for debugging purposes. \n",
        "\n",
        "class ResidualBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3,\n",
        "                            stride = stride, padding = 1),\n",
        "            torch.nn.BatchNorm2d(out_channels),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3,\n",
        "                                     stride = 1, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2(output)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        else:\n",
        "            residual = x\n",
        "        output = output + residual\n",
        "        output = self.relu(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(self, block, layers, num_classes = 7000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.num_channels = 64\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride = 2, padding=3),\n",
        "            torch.nn.BatchNorm2d(self.num_channels),\n",
        "            torch.nn.ReLU())\n",
        "\n",
        "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer0 = self.layer_blocks(block, 64, layers[0], stride=1)\n",
        "        self.layer1 = self.layer_blocks(block, 128, layers[1], stride=2)\n",
        "        self.layer2 = self.layer_blocks(block, 256, layers[2], stride=2)\n",
        "        self.layer3 = self.layer_blocks(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = torch.nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = torch.nn.Linear(512, self.num_classes)\n",
        "\n",
        "\n",
        "    def layer_blocks(self, block, num_filters, num_blocks, stride = 1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (num_filters != self.num_channels):\n",
        "            downsample = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_channels=self.num_channels, out_channels=num_filters, kernel_size=1, stride = stride),\n",
        "                torch.nn.BatchNorm2d(num_filters)\n",
        "            )\n",
        "        else:\n",
        "            downsample = None\n",
        "        layers = [block(self.num_channels, num_filters, stride, downsample)]\n",
        "        self.num_channels = num_filters\n",
        "\n",
        "        for i in range(1, num_blocks):\n",
        "            layers.append(block(self.num_channels, num_filters))\n",
        "\n",
        "        return torch.nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-14T04:14:36.130768Z",
          "iopub.execute_input": "2023-03-14T04:14:36.131174Z",
          "iopub.status.idle": "2023-03-14T04:14:36.308494Z",
          "shell.execute_reply.started": "2023-03-14T04:14:36.131140Z",
          "shell.execute_reply": "2023-03-14T04:14:36.307474Z"
        },
        "trusted": true,
        "id": "ZrtztkaUZYoi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(DEVICE)\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:24.351194Z",
          "iopub.execute_input": "2023-03-14T04:15:24.351940Z",
          "iopub.status.idle": "2023-03-14T04:15:27.020775Z",
          "shell.execute_reply.started": "2023-03-14T04:15:24.351898Z",
          "shell.execute_reply": "2023-03-14T04:15:27.019558Z"
        },
        "trusted": true,
        "id": "gLNDUKaSZYoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup everything for training"
      ],
      "metadata": {
        "id": "KZCn0qHuZRKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/IDL/HW2P2/models/ResNet34-restart-2.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing = 0.1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'], momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.2, patience = 2)\n",
        "# TODO: Implement a scheduler (Optional but Highly Recommended)\n",
        "# You can try ReduceLRonPlateau, StepLR, MultistepLR, CosineAnnealing, etc.\n",
        "scaler = torch.cuda.amp.GradScaler() # Good news. We have FP16 (Mixed precision training) implemented for you\n",
        "# It is useful only in the case of compatible GPUs such as T4/V100"
      ],
      "metadata": {
        "id": "UowI9OcUYPjP",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:35.328497Z",
          "iopub.execute_input": "2023-03-14T04:15:35.329484Z",
          "iopub.status.idle": "2023-03-14T04:15:35.337859Z",
          "shell.execute_reply.started": "2023-03-14T04:15:35.329430Z",
          "shell.execute_reply": "2023-03-14T04:15:35.336372Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's train!"
      ],
      "metadata": {
        "id": "dzM11HtcboYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    # Progress Bar \n",
        "    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5) \n",
        "\n",
        "    num_correct = 0\n",
        "    total_loss  = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "        \n",
        "        optimizer.zero_grad() # Zero gradients\n",
        "\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        \n",
        "        with torch.cuda.amp.autocast(): # This implements mixed precision. Thats it! \n",
        "            outputs = model(images)\n",
        "            loss    = criterion(outputs, labels)\n",
        "\n",
        "        # Update no. of correct predictions & loss as we iterate\n",
        "        num_correct     += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
        "        total_loss      += float(loss.item())\n",
        "\n",
        "        # tqdm lets you add some details so you can monitor training as you train.\n",
        "        batch_bar.set_postfix(\n",
        "            acc         = \"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss        = \"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct = num_correct,\n",
        "            lr          = \"{:.06f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "        )\n",
        "        \n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() \n",
        "\n",
        "        # TODO? Depending on your choice of scheduler,\n",
        "        # You may want to call some schdulers inside the train function. What are these?\n",
        "      \n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    acc         = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss  = float(total_loss / len(dataloader))\n",
        "\n",
        "    return acc, total_loss"
      ],
      "metadata": {
        "id": "bgSw6iJJavBZ",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:48.458513Z",
          "iopub.execute_input": "2023-03-14T04:15:48.458892Z",
          "iopub.status.idle": "2023-03-14T04:15:48.469860Z",
          "shell.execute_reply.started": "2023-03-14T04:15:48.458859Z",
          "shell.execute_reply": "2023-03-14T04:15:48.468525Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader, criterion):\n",
        "  \n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
        "\n",
        "    num_correct = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "        \n",
        "        # Move images to device\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        \n",
        "        # Get model outputs\n",
        "        with torch.inference_mode():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss=\"{:.06f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct=num_correct)\n",
        "\n",
        "        batch_bar.update()\n",
        "        \n",
        "    batch_bar.close()\n",
        "    acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss = float(total_loss / len(dataloader))\n",
        "    return acc, total_loss"
      ],
      "metadata": {
        "id": "m5V2UdnpdEoK",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:50.544463Z",
          "iopub.execute_input": "2023-03-14T04:15:50.545142Z",
          "iopub.status.idle": "2023-03-14T04:15:50.557642Z",
          "shell.execute_reply.started": "2023-03-14T04:15:50.545103Z",
          "shell.execute_reply": "2023-03-14T04:15:50.556347Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect() # These commands help you when you face CUDA OOM error\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "cmotca6pcLLY",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:51.457285Z",
          "iopub.execute_input": "2023-03-14T04:15:51.458226Z",
          "iopub.status.idle": "2023-03-14T04:15:51.645467Z",
          "shell.execute_reply.started": "2023-03-14T04:15:51.458172Z",
          "shell.execute_reply": "2023-03-14T04:15:51.644413Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb"
      ],
      "metadata": {
        "id": "2mBgKGkXLrdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"cce3530b8ee00a25da9393f98f6b0142435348a3\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
      ],
      "metadata": {
        "id": "Ix62_BkaLr_D",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:54.026555Z",
          "iopub.execute_input": "2023-03-14T04:15:54.027612Z",
          "iopub.status.idle": "2023-03-14T04:15:55.945602Z",
          "shell.execute_reply.started": "2023-03-14T04:15:54.027559Z",
          "shell.execute_reply": "2023-03-14T04:15:55.944396Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your wandb run\n",
        "run = wandb.init(\n",
        "    name = \"ResNet34-aug\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    #id = 'vo24kiuj', #Insert specific run id here if you want to resume a previous run\n",
        "    #resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw2p2-krana\", ### Project should be created in your wandb account \n",
        "    config = config ### Wandb Config for your run\n",
        ")"
      ],
      "metadata": {
        "id": "VG0vmsmbRYEi",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:15:55.948020Z",
          "iopub.execute_input": "2023-03-14T04:15:55.948716Z",
          "iopub.status.idle": "2023-03-14T04:16:26.786179Z",
          "shell.execute_reply.started": "2023-03-14T04:15:55.948673Z",
          "shell.execute_reply": "2023-03-14T04:16:26.784813Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "SQkRw1FvLqYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_valacc = 0.0\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    train_acc, train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    \n",
        "    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.06f}\".format(\n",
        "        epoch + 1,\n",
        "        config['epochs'],\n",
        "        train_acc,\n",
        "        train_loss,\n",
        "        curr_lr))\n",
        "    \n",
        "    val_acc, val_loss = validate(model, valid_loader, criterion)\n",
        "    \n",
        "    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n",
        "\n",
        "    wandb.log({\"train_loss\":train_loss, 'train_Acc': train_acc, 'validation_Acc':val_acc, \n",
        "               'validation_loss': val_loss, \"learning_Rate\": curr_lr})\n",
        "    \n",
        "    # If you are using a scheduler in your train function within your iteration loop, you may want to log\n",
        "    # your learning rate differently \n",
        "\n",
        "    # #Save model in drive location if val_acc is better than best recorded val_acc\n",
        "    if val_acc >= best_valacc:\n",
        "      #path = os.path.join(root, model_directory, 'checkpoint' + '.pth')\n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict':model.state_dict(),\n",
        "                  'optimizer_state_dict':optimizer.state_dict(),\n",
        "                  #'scheduler_state_dict':scheduler.state_dict(),\n",
        "                  'val_acc': val_acc, \n",
        "                  'epoch': epoch}, '/content/drive/MyDrive/IDL/HW2P2/models/ResNet34-restart-2.pth')\n",
        "      torch.save({'model_state_dict':model.state_dict(),\n",
        "                  'optimizer_state_dict':optimizer.state_dict(),\n",
        "                  #'scheduler_state_dict':scheduler.state_dict(),\n",
        "                  'val_acc': val_acc, \n",
        "                  'epoch': epoch}, '/content/ResNet34-restart-2.pth')\n",
        "      best_valacc = val_acc\n",
        "      wandb.save('ResNet34-restart-2.pth')\n",
        "    scheduler.step()\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "EqWO8Edb0BK2",
        "execution": {
          "iopub.status.busy": "2023-03-14T04:16:26.791839Z",
          "iopub.execute_input": "2023-03-14T04:16:26.792242Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXlAp2A27zVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}